{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "rhc_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNqSVJZFUR-L"
      },
      "source": [
        "# Data Manipulation Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51KJCJ2wU7AB"
      },
      "source": [
        "retail = pd.read_csv('/content/Train.csv')\n",
        "retail_test = pd.read_csv('/content/Test.csv')\n",
        "retail_data = retail.copy()\n",
        "retail_test_data = retail_test.copy()\n",
        "\n",
        "#Drop Duplicate rows\n",
        "retail_data.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "#Only dropped one outlier\n",
        "retail_data.drop(retail_data.loc[retail_data['UnitPrice']>35000,:].index,inplace=True)\n",
        "\n",
        "# #No missing values\n",
        "# import missingno as msno\n",
        "# msno.matrix(retail_test)\n",
        "# print(retail_test.isna().sum())\n",
        "#Seperate Categorical and Numerical Columns\n",
        "cat_cols = retail_data.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print(cat_cols)\n",
        "\n",
        "num_cols = retail_data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "print(num_cols)\n",
        "\n",
        "retail_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtBEsphQdSN6"
      },
      "source": [
        "def drop_irrelavant_columns(df):\n",
        "  df.drop(columns=['InvoiceNo','Description','Quantity','CustomerID','Country'],inplace=True)\n",
        "\n",
        "def sample_by_hour_set_index(df):\n",
        "  df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "  df.set_index('InvoiceDate',inplace=True)\n",
        "  df.index = pd.to_datetime(df.index.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "  df.sort_index(inplace=True)\n",
        "  df.resample(rule='H').mean().fillna(method ='ffill', inplace = True)\n",
        "\n",
        "def convert_InvoiceDate_to_features(df):\n",
        "  df['year'] = df.index.year\n",
        "  df['month'] = df.index.month\n",
        "  df['day'] = df.index.day\n",
        "  df['hour'] = df.index.hour\n",
        "  df['minute'] = df.index.minute\n",
        "  return df\n",
        "\n",
        "\n",
        "def convert_column_to_dummies(df,colname):\n",
        "  dummies = pd.get_dummies(df[colname])\n",
        "\n",
        "  for col in dummies.columns:\n",
        "    df[col] = dummies[col]\n",
        "\n",
        "  df.drop(columns=[colname],inplace=True)\n",
        "\n",
        "def convert_unit_price_to_supervised(df):\n",
        "  reframed = series_to_supervised(df['UnitPrice'].values, n_in=7, n_out=1, dropnan=True)\n",
        "  for col in reframed.columns:\n",
        "        df.assign(col = reframed[col].values)\n",
        "  return df\n",
        "\n",
        "def series_to_supervised(data, n_in=7, n_out=1, dropnan=True):\n",
        "    n_vars = 1\n",
        "    dff = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(dff.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    # for i in range(0, n_out):\n",
        "    # \tcols.append(dff.shift(-i))\n",
        "    # \tif i == 0:\n",
        "    # \t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "    # \telse:\n",
        "    # \t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.fillna(method='bfill', inplace=True)\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP2hw5FbNMuq"
      },
      "source": [
        "retail_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lny3p5eBBNI-"
      },
      "source": [
        "drop_irrelavant_columns(retail_data)\n",
        "drop_irrelavant_columns(retail_test_data)\n",
        "\n",
        "sample_by_hour_set_index(retail_data)\n",
        "sample_by_hour_set_index(retail_test_data)\n",
        "\n",
        "supervised_combined = convert_unit_price_to_supervised(retail_data)\n",
        "\n",
        "supervised_combined = convert_InvoiceDate_to_features(supervised_combined)\n",
        "retail_test_data = convert_InvoiceDate_to_features(retail_test_data)\n",
        "\n",
        "convert_column_to_dummies(supervised_combined,'StockCode')\n",
        "convert_column_to_dummies(retail_test_data,'StockCode')\n",
        "\n",
        "retail_test_data.dropna(inplace=True)\n",
        "model_ready_test_data = retail_test_data.values\n",
        "to_predict_data = model_ready_test_data.reshape((model_ready_test_data.shape[0], 1, model_ready_test_data.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbai3aMuIW1D"
      },
      "source": [
        "supervised_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQi32gdSLR6S"
      },
      "source": [
        "n_train_time = int(supervised_combined.shape[0]*0.8)\n",
        "supervised_combined.loc[:n_train_time,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib578pYsEcqI"
      },
      "source": [
        "# split into train and test sets\n",
        "values = supervised_combined.values\n",
        "\n",
        "n_train_time = int(len(supervised_combined)*0.8)\n",
        "train = values[:n_train_time, :]\n",
        "test = values[n_train_time:, :]\n",
        "##test = values[n_train_time:n_test_time, :]\n",
        "# split into input and outputs\n",
        "train_X, train_y = train[:, 1:], train[:, 0]\n",
        "test_X, test_y = test[:, 1:], test[:, 0]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}