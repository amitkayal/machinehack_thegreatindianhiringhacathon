{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TheGreatIndianHiringHackathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNqSVJZFUR-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4496a2d0-8a9f-45f0-e724-9ff7da1449fe"
      },
      "source": [
        "# Data Manipulation Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "# Vizualization Libraries\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# pre-processing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ML model Libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#statsmodels\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.arima_model import ARMA\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.arima_process import ArmaProcess\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "!pip install pmdarima\n",
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "## for Deep-learing:\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "import itertools\n",
        "from keras.layers import LSTM, RepeatVector, TimeDistributed, Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.6/dist-packages (1.7.1)\n",
            "Requirement already satisfied: statsmodels<0.12,>=0.11 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (0.11.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (0.22.2.post1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (1.4.1)\n",
            "Requirement already satisfied: Cython<0.29.18,>=0.29 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (0.29.17)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (1.1.4)\n",
            "Requirement already satisfied: setuptools<50.0.0 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (49.6.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels<0.12,>=0.11->pmdarima) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pmdarima) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pmdarima) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels<0.12,>=0.11->pmdarima) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51KJCJ2wU7AB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9b64031d-7771-4a72-adc5-73f6acab2370"
      },
      "source": [
        "retail = pd.read_csv('/content/drive/My Drive/TheGreatIndianHiringHackathon/Train.csv')\n",
        "retail_test = pd.read_csv('/content/drive/My Drive/TheGreatIndianHiringHackathon/Test.csv')\n",
        "retail_data = retail.copy()\n",
        "retail_test_data = retail_test.copy()\n",
        "\n",
        "#Drop Duplicate rows\n",
        "retail_data.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "#Only dropped one outlier\n",
        "retail_data.drop(retail_data.loc[retail_data['UnitPrice']>35000,:].index,inplace=True)\n",
        "\n",
        "# #No missing values\n",
        "# import missingno as msno\n",
        "# msno.matrix(retail_test)\n",
        "# print(retail_test.isna().sum())\n",
        "#Seperate Categorical and Numerical Columns\n",
        "cat_cols = retail_data.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print(cat_cols)\n",
        "\n",
        "num_cols = retail_data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "print(num_cols)\n",
        "\n",
        "retail_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['InvoiceDate']\n",
            "['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'UnitPrice', 'CustomerID', 'Country']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6141</td>\n",
              "      <td>1583</td>\n",
              "      <td>144</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-05-06 16:54:00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>14056.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6349</td>\n",
              "      <td>1300</td>\n",
              "      <td>3682</td>\n",
              "      <td>6</td>\n",
              "      <td>2011-05-11 07:35:00</td>\n",
              "      <td>1.95</td>\n",
              "      <td>13098.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16783</td>\n",
              "      <td>2178</td>\n",
              "      <td>1939</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-11-20 13:20:00</td>\n",
              "      <td>5.95</td>\n",
              "      <td>15044.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16971</td>\n",
              "      <td>2115</td>\n",
              "      <td>2983</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-11-22 12:07:00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>15525.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6080</td>\n",
              "      <td>1210</td>\n",
              "      <td>2886</td>\n",
              "      <td>12</td>\n",
              "      <td>2011-05-06 09:00:00</td>\n",
              "      <td>1.65</td>\n",
              "      <td>13952.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   InvoiceNo  StockCode  Description  ...  UnitPrice CustomerID  Country\n",
              "0       6141       1583          144  ...       3.75    14056.0       35\n",
              "1       6349       1300         3682  ...       1.95    13098.0       35\n",
              "2      16783       2178         1939  ...       5.95    15044.0       35\n",
              "3      16971       2115         2983  ...       0.83    15525.0       35\n",
              "4       6080       1210         2886  ...       1.65    13952.0       35\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8a33gnl1T4A"
      },
      "source": [
        "# sorted = retail_data.sort_values(by='InvoiceDate')\n",
        "# grouped = retail_data.groupby('StockCode')['UnitPrice']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UugNoc5283C"
      },
      "source": [
        "# fig = px.line(sorted,x=sorted['InvoiceDate'],y='UnitPrice',color='StockCode')\n",
        "# fig.show()\n",
        "# peculiar_stock = ['3683','3681','3678','3680','3679','3680','3678','1511']\n",
        "# sc_2384 = sorted.loc[sorted['StockCode']==2384,:]\n",
        "# fig = px.line(sc_2384,x=sc_2384['InvoiceDate'],y='UnitPrice')\n",
        "# fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5cgwXMwln7i"
      },
      "source": [
        "truevalues = []\n",
        "for i in retail_test_data['StockCode'].values:\n",
        "  if i in [3683,3681,3678,3680,3679,3680,3678,1511]:\n",
        "    truevalues.append({i:retail_test_data[retail_test_data['StockCode'] == i]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnKAcPdMNIdx"
      },
      "source": [
        "#Common Methods\n",
        "\n",
        "#Quantity cant be negative\n",
        "def make_quantity_abs(df):\n",
        "  df['Quantity'] = df['Quantity'].abs()\n",
        "\n",
        "def drop_columns(df1,df2,columnList):\n",
        "  df1.drop(columns=columnList,inplace=True)\n",
        "  df2.drop(columns=columnList,inplace=True)\n",
        "\n",
        "def set_invoicedate_index_sort(df):\n",
        "  df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "  df.set_index('InvoiceDate',inplace=True)\n",
        "  df.index = pd.to_datetime(df.index.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "  df.sort_index(inplace=True)\n",
        "  df.resample()\n",
        "  return df\n",
        "\n",
        "def change_to_appropriate_type(df):\n",
        "  df['StockCode'] = df['StockCode'].astype('string')\n",
        "  df['CustomerID'] = df['CustomerID'].astype('int')\n",
        "  df['CustomerID'] = df['CustomerID'].astype('string')\n",
        "\n",
        "def code_country(df):\n",
        "  df.loc[df['Country']=='35','Country'] = 'country35'\n",
        "  df.loc[df['Country']!='country35','Country'] = 'OtherCountry'\n",
        "\n",
        "def replace_stockcode_with_quantity(train_df,test_df):\n",
        "  #Highest Quantity purchase\n",
        "  train_temp = train_df.copy()\n",
        "  train_quantity_sum = train_temp[['StockCode','Quantity']].groupby(['StockCode']).sum().copy()\n",
        "  train_quantity_sum.index = train_quantity_sum.index.astype('int')\n",
        "  train_quantity_sum.sort_values(by='StockCode',inplace=True)\n",
        "\n",
        "  test_temp = test_df.copy()\n",
        "  test_quantity_sum = test_temp[['StockCode','Quantity']].groupby(['StockCode']).sum().copy()\n",
        "  test_quantity_sum.index = test_quantity_sum.index.astype('int')\n",
        "  test_quantity_sum.sort_values(by='StockCode',inplace=True)\n",
        "\n",
        "  #replacing train with train quantity sum\n",
        "  train_df = pd.DataFrame(train_df)\n",
        "  train_df.replace(train_quantity_sum.to_dict(),inplace=True)\n",
        "  train_df.rename(columns={'StockCode':'StockCodeQuantity'},inplace=True)\n",
        "\n",
        "  #replacing test with train quantity sum\n",
        "  train_df = pd.DataFrame(test_df)\n",
        "  test_df.replace(train_quantity_sum.to_dict(),inplace=True)\n",
        "  #balance if any\n",
        "  test_df.replace(test_quantity_sum.to_dict(),inplace=True)\n",
        "  test_df.rename(columns={'StockCode':'StockCodeQuantity'},inplace=True)\n",
        "\n",
        "  train_df.drop(columns=['Quantity'],inplace=True)\n",
        "  test_df.drop(columns=['Quantity'],inplace=True)\n",
        "\n",
        "def add_unique_customer_count_per_day(df):\n",
        "  #Adding unique Customer count\n",
        "  df['UniqueCustomerCount'] = [datetime.datetime.strftime(df.index[dt], '%Y-%m-%d') for dt in range(len(df.index))]\n",
        "  replace_uniqueCustomerCount = df.groupby('UniqueCustomerCount')['CustomerID'].count().to_dict()\n",
        "  df['UniqueCustomerCount'].replace(replace_uniqueCustomerCount,inplace=True)\n",
        "\n",
        "def convert_column_to_dummies(df,colname):\n",
        "  dummies = pd.get_dummies(df[colname])\n",
        "\n",
        "  for col in dummies.columns:\n",
        "    df[col] = dummies[col]\n",
        "\n",
        "  df.drop(columns=[colname],inplace=True)\n",
        "\n",
        "def categorize_y(y):\n",
        "  y = np.round(y)\n",
        "  y = y.astype(int)\n",
        "  for i in range(len(y)):\n",
        "    if int(y[i]) == 1:\n",
        "      y[i] = '1'\n",
        "    elif int(y[i]) == 2:\n",
        "      y[i] = '2'\n",
        "    elif int(y[i]) == 3:\n",
        "      y[i] = '3'\n",
        "    elif int(y[i]) == 4:\n",
        "      y[i] = '4'\n",
        "    elif int(y[i]) == 5:\n",
        "      y[i] = '5'\n",
        "    elif int(y[i]) == 6:\n",
        "      y[i] = '6'\n",
        "    elif int(y[i]) == 7:\n",
        "      y[i] = '7'\n",
        "    elif int(y[i]) == 8:\n",
        "      y[i] = '8'\n",
        "    elif int(y[i]) == 9:\n",
        "      y[i] = '9'\n",
        "    elif int(y[i]) == 10:\n",
        "      y[i] = '10'\n",
        "    elif int(y[i]) > 11 & int(y[i]) <= 15:\n",
        "      y[i] = '15'\n",
        "    elif int(y[i]) > 15 & int(y[i]) <= 20:\n",
        "      y[i] = '20'\n",
        "    elif int(y[i]) > 20 & int(y[i]) <= 50:\n",
        "      y[i] = '50'\n",
        "    elif int(y[i]) > 50 & int(y[i]) <= 100:\n",
        "      y[i] = '100'\n",
        "    else:\n",
        "      y[i] = '500'\n",
        "  \n",
        "  return y\n",
        "\n",
        "scaler = StandardScaler(with_mean=True,with_std=True)\n",
        "def perform_scaling(toscale):\n",
        "  global scaler\n",
        "  scaler = StandardScaler(with_mean=True,with_std=True)\n",
        "  return pd.DataFrame(scaler.fit_transform(toscale),columns=toscale.columns,index=toscale.index)\n",
        "\n",
        "def execute_known_y_test(df,test_size=0.3,shuffleBool=False):\n",
        "  X = df[['StockCodeQuantity','UniqueCustomerCount',\t'OtherCountry',\t'country35']]\n",
        "  y = df['UnitPrice']\n",
        "  X[['StockCodeQuantity','UniqueCustomerCount']] = perform_scaling(df[['StockCodeQuantity','UniqueCustomerCount']])\n",
        "  y = categorize_y(y)\n",
        "  return train_test_split(X, y, test_size=test_size, random_state=42,shuffle=shuffleBool)\n",
        "\n",
        "    \n",
        "def execute_unknown_y_test(df1,df2):\n",
        "  ssc = StandardScaler(with_mean=True,with_std=True)\n",
        "\n",
        "  x_train = df1[['UniqueCustomerCount']]\n",
        "  x_train[['UniqueCustomerCount']] = perform_scaling(x_train[['UniqueCustomerCount']])\n",
        "  y_train = perform_scaling(df1)\n",
        "  # y_train = categorize_y(y_train)\n",
        "\n",
        "  #retail_test_data\n",
        "  x_test = df2[['UniqueCustomerCount']]\n",
        "  x_test[['UniqueCustomerCount']] = perform_scaling(x_test[['UniqueCustomerCount']])\n",
        "\n",
        "  return x_train, y_train, x_test\n",
        "\n",
        "def save_export_predicted_values(test_data,y_pred,save_name):\n",
        "\n",
        "  test_data['UnitPrice'] = y_pred\n",
        "  sorted_predicted_dataframe = test_data.sort_values('order')\n",
        "  UnitPrice = pd.DataFrame(sorted_predicted_dataframe['UnitPrice'].astype('int').values,columns=['UnitPrice'])\n",
        "  UnitPrice.to_csv('/content/drive/My Drive/TheGreatIndianHiringHackathon/'+save_name+'.csv', index=False, index_label=None)\n",
        "\n",
        "def match_predictions(predictions,test_data,save_name):\n",
        "  predictions = pd.DataFrame(predictions,columns=['Predictions'])\n",
        "  predictions['Predictions'] = np.round(predictions['Predictions'],decimals=2)\n",
        "  predictions['pred'] = predictions.index.strftime('%Y-%m-%d').astype('string')\n",
        "  dictionary_map = pd.Series(predictions['Predictions'].values,index=predictions['pred']).to_dict()\n",
        "\n",
        "  test_data['UnitPrice'] = test_data.index.strftime('%Y-%m-%d').astype('string')\n",
        "  test_data['UnitPrice'].replace(dictionary_map,inplace=True)\n",
        "  sorted_predicted_dataframe = test_data.sort_values('order')\n",
        "  UnitPrice = pd.DataFrame(sorted_predicted_dataframe['UnitPrice'].astype('float').values,columns=['UnitPrice'])\n",
        "  UnitPrice.to_csv('/content/drive/My Drive/TheGreatIndianHiringHackathon/'+save_name+'.csv', index=False, index_label=None)\n",
        "\n",
        "def remove_non_business_hours(df1):\n",
        "  hour_resampled_data_index = df1.index\n",
        "  to_drop_index = []\n",
        "  for t in hour_resampled_data_index:\n",
        "    if t.hour < 8 | t.hour > 18:\n",
        "      to_drop_index.append(t)\n",
        "\n",
        "  df1.drop(index=to_drop_index,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0fyEMAdqebx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "52064694-1029-48c1-d44e-5846b3128fa4"
      },
      "source": [
        "retail_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6141</td>\n",
              "      <td>1583</td>\n",
              "      <td>144</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-05-06 16:54:00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>14056.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6349</td>\n",
              "      <td>1300</td>\n",
              "      <td>3682</td>\n",
              "      <td>6</td>\n",
              "      <td>2011-05-11 07:35:00</td>\n",
              "      <td>1.95</td>\n",
              "      <td>13098.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16783</td>\n",
              "      <td>2178</td>\n",
              "      <td>1939</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-11-20 13:20:00</td>\n",
              "      <td>5.95</td>\n",
              "      <td>15044.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16971</td>\n",
              "      <td>2115</td>\n",
              "      <td>2983</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-11-22 12:07:00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>15525.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6080</td>\n",
              "      <td>1210</td>\n",
              "      <td>2886</td>\n",
              "      <td>12</td>\n",
              "      <td>2011-05-06 09:00:00</td>\n",
              "      <td>1.65</td>\n",
              "      <td>13952.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   InvoiceNo  StockCode  Description  ...  UnitPrice CustomerID  Country\n",
              "0       6141       1583          144  ...       3.75    14056.0       35\n",
              "1       6349       1300         3682  ...       1.95    13098.0       35\n",
              "2      16783       2178         1939  ...       5.95    15044.0       35\n",
              "3      16971       2115         2983  ...       0.83    15525.0       35\n",
              "4       6080       1210         2886  ...       1.65    13952.0       35\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIgKgM5iNFji"
      },
      "source": [
        "make_quantity_abs(retail_data)\n",
        "make_quantity_abs(retail_test_data)\n",
        "\n",
        "drop_columns(retail_data,retail_test_data,['Description','InvoiceNo','Country'])\n",
        "\n",
        "retail_data = set_invoicedate_index_sort(retail_data)\n",
        "retail_test_data['order'] = range(0,retail_test_data.shape[0])\n",
        "retail_test_data = set_invoicedate_index_sort(retail_test_data)\n",
        "\n",
        "change_to_appropriate_type(retail_data)\n",
        "change_to_appropriate_type(retail_test_data)\n",
        "\n",
        "# code_country(retail_data)\n",
        "# code_country(retail_test_data)\n",
        "\n",
        "#replace_stockcode_with_quantity(retail_data,retail_test_data)\n",
        "\n",
        "#add_unique_customer_count_per_day(retail_data)\n",
        "#add_unique_customer_count_per_day(retail_test_data)\n",
        "\n",
        "#convert_column_to_dummies(retail_data,'Country')\n",
        "#convert_column_to_dummies(retail_test_data,'Country')\n",
        "\n",
        "hour_resampled_retail_data = retail_data.resample(rule='H', closed=\"right\", label=\"left\", base=23).mean().fillna(0)\n",
        "hour_resampled_retail_test_data = retail_test_data.resample(rule='H', closed=\"right\", label=\"left\", base=23).mean().fillna(0)\n",
        "\n",
        "remove_non_business_hours(retail_data)\n",
        "#remove_non_business_hours(retail_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8ruBxdHgAw6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "67f1a4e3-3fb1-42b0-c4d8-a663358ef175"
      },
      "source": [
        "stock_code_dummies = pd.get_dummies(retail_data['StockCode'])\n",
        "stock_code_dummies.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>1001</th>\n",
              "      <th>1002</th>\n",
              "      <th>1003</th>\n",
              "      <th>1004</th>\n",
              "      <th>1005</th>\n",
              "      <th>1006</th>\n",
              "      <th>1007</th>\n",
              "      <th>1008</th>\n",
              "      <th>1009</th>\n",
              "      <th>101</th>\n",
              "      <th>1010</th>\n",
              "      <th>1011</th>\n",
              "      <th>1012</th>\n",
              "      <th>1013</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>102</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "      <th>1024</th>\n",
              "      <th>1025</th>\n",
              "      <th>1026</th>\n",
              "      <th>1027</th>\n",
              "      <th>1028</th>\n",
              "      <th>1029</th>\n",
              "      <th>103</th>\n",
              "      <th>1030</th>\n",
              "      <th>1031</th>\n",
              "      <th>1032</th>\n",
              "      <th>...</th>\n",
              "      <th>963</th>\n",
              "      <th>964</th>\n",
              "      <th>965</th>\n",
              "      <th>966</th>\n",
              "      <th>967</th>\n",
              "      <th>968</th>\n",
              "      <th>969</th>\n",
              "      <th>97</th>\n",
              "      <th>970</th>\n",
              "      <th>971</th>\n",
              "      <th>972</th>\n",
              "      <th>973</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>979</th>\n",
              "      <th>98</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "      <th>99</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-12-01 08:26:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-01 08:26:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-01 08:26:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-01 08:26:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-01 08:26:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3582 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0  1  10  100  1000  1001  ...  994  995  996  997  998  999\n",
              "InvoiceDate                                     ...                              \n",
              "2010-12-01 08:26:00  0  0   0    0     0     0  ...    0    0    0    0    0    0\n",
              "2010-12-01 08:26:00  0  0   0    0     0     0  ...    0    0    0    0    0    0\n",
              "2010-12-01 08:26:00  0  0   0    0     0     0  ...    0    0    0    0    0    0\n",
              "2010-12-01 08:26:00  0  0   0    0     0     0  ...    0    0    0    0    0    0\n",
              "2010-12-01 08:26:00  0  0   0    0     0     0  ...    0    0    0    0    0    0\n",
              "\n",
              "[5 rows x 3582 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cnozOH-sElA"
      },
      "source": [
        " retail_data = pd.concat([retail_data, pd.get_dummies(retail_data['StockCode'])], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e45Lt_xL2iPc"
      },
      "source": [
        "# Create an offset \n",
        "fig = px.line(hour_resampled_retail_data, x=hour_resampled_retail_data.index,y='UnitPrice')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efJHeEHlZfvL"
      },
      "source": [
        "retail_data_resampled = hour_resampled_retail_data['UnitPrice']\n",
        "plot_pacf(retail_data_resampled,alpha=0.05,lags=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28sz-Yb489BS"
      },
      "source": [
        "plot_pacf(retail_data_resampled,alpha=0.05,lags=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXRsHH0y-rOn"
      },
      "source": [
        "# bic_aic_sum = []\n",
        "# result = []\n",
        "# for i in range(1,3):\n",
        "#     for k in range(1,3):\n",
        "#         newarray = retail_data_resampled-retail_data_resampled.shift(k)\n",
        "#         ma_mod = ARMA(newarray.dropna(), order=(i,k))\n",
        "#         ma_res = ma_mod.fit()\n",
        "#         result.append({'aic':ma_res.aic,'bic':ma_res.bic,'bic_aic_sum':ma_res.aic+ma_res.bic,'res':ma_res,'ar_index':i,'ma_index':k})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgtc4cwO_SoY"
      },
      "source": [
        "# #bic aic sum lowest for arima(1,0,1)\n",
        "# print(result[0]['res'].summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJG4aqjrHjvX"
      },
      "source": [
        "# model = sm.tsa.ARMA(retail_data_resampled, (1, 1))\n",
        "# results = model.fit()\n",
        "# predictions = results.predict(start=retail_data_resampled.index[0],end=retail_data_resampled.index[-1])\n",
        "# plt.figure(figsize=(20,5))\n",
        "# ax = plt.plot(retail_data_resampled)\n",
        "# ax = plt.plot(predictions)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y39t-I2OqJBU"
      },
      "source": [
        "# x_train, x_test, y_train, y_test = execute_known_y_test(retail_data,0.3,False)\n",
        "\n",
        "# step_wise = auto_arima(y_train, exogenous= x_train,\n",
        "#                        start_p=1, start_q=1, \n",
        "#                        max_p=7, max_q=7, d=1, max_d=7, \n",
        "#                        trace=True, error_action='ignore', suppress_warnings=True, stepwise=True) #seasonal=True/ trend='c'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNpT88xk1OX9"
      },
      "source": [
        "Performing stepwise search to minimize aic\n",
        " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=inf, Time=120.95 sec\n",
        " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=2670770.627, Time=7.48 sec\n",
        " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=2613848.562, Time=15.23 sec\n",
        " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=inf, Time=101.67 sec\n",
        " ARIMA(0,1,0)(0,0,0)[0]             : AIC=2670768.800, Time=73.47 sec\n",
        " ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=2590577.225, Time=11.09 sec\n",
        " ARIMA(3,1,0)(0,0,0)[0] intercept   : AIC=2577799.714, Time=22.06 sec\n",
        " ARIMA(4,1,0)(0,0,0)[0] intercept   : AIC=2569754.189, Time=27.74 sec\n",
        " ARIMA(5,1,0)(0,0,0)[0] intercept   : AIC=2564327.959, Time=34.78 sec\n",
        " ARIMA(6,1,0)(0,0,0)[0] intercept   : AIC=2560287.625, Time=44.12 sec\n",
        " ARIMA(7,1,0)(0,0,0)[0] intercept   : AIC=2557165.078, Time=47.20 sec\n",
        " ARIMA(7,1,1)(0,0,0)[0] intercept   : AIC=inf, Time=697.01 sec\n",
        " ARIMA(6,1,1)(0,0,0)[0] intercept   : AIC=inf, Time=639.02 sec\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTdpWstv1qTp"
      },
      "source": [
        "# plt.rcParams['agg.path.chunksize'] = 10000\n",
        "# plt.rcParams.update({'figure.figsize': (20,10)})\n",
        "# frequency = 60\n",
        "# # multiplicative = sm.tsa.seasonal_decompose(retail_data['UnitPrice'].to_frame(),period=frequency,model='multiplicative')\n",
        "# # multiplicative.plot().suptitle('Multiplicative Decompose', fontsize=22)\n",
        "# # plt.show()\n",
        "\n",
        "# additive = sm.tsa.seasonal_decompose(retail_data['UnitPrice'].to_frame(),freq=frequency,model='additive')\n",
        "# additive.plot().suptitle('Additive Decompose', fontsize=22)\n",
        "# plt.show()\n",
        "# plt.rcParams.update({'figure.figsize': (15,5)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJI_uBP6IEQ"
      },
      "source": [
        "# x_train, y_train, x_test = execute_unknown_y_test(hour_resampled_retail_data,hour_resampled_retail_test_data)\n",
        "# forecast = sarimax_results.forecast(steps=test_size-1, exog=test_X[3])\n",
        "# x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkaL6C6JPlj_"
      },
      "source": [
        "hour_resampled_retail_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7nF1Omw6ccK"
      },
      "source": [
        "# converting into supervised learning\n",
        "# train_time_samples = x_train.index\n",
        "# test_time_samples = x_test.index\n",
        "# extra = []\n",
        "# for i in test_time_samples:\n",
        "#   if(i not in train_time_samples):\n",
        "#     extra.append(i)\n",
        "\n",
        "# print(extra)\n",
        "#all test samples are there in train samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR3IgOe7Riey"
      },
      "source": [
        "print(scaled_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jodQeDNQ3_o"
      },
      "source": [
        "# ssc = StandardScaler(with_mean=True,with_std=True)\n",
        "# minmaxscaler = MinMaxScaler()\n",
        "# scaled_y = minmaxscaler.fit_transform(hour_resampled_retail_data['UnitPrice'].values.reshape(1,-1))\n",
        "# scaled_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lny3p5eBBNI-"
      },
      "source": [
        "def series_to_supervised(data, n_in=7, n_out=1, dropnan=True):\n",
        "\tn_vars = 1\n",
        "\tdff = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(dff.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\t# for i in range(0, n_out):\n",
        "\t# \tcols.append(dff.shift(-i))\n",
        "\t# \tif i == 0:\n",
        "\t# \t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t# \telse:\n",
        "\t# \t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwfg21p7Bc_r"
      },
      "source": [
        "reframed = series_to_supervised(hour_resampled_retail_data['UnitPrice'].values, n_in=7, n_out=1, dropnan=True)\n",
        "reframed['actual'] = hour_resampled_retail_data['UnitPrice'].values[:-7]\n",
        "reframed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib578pYsEcqI"
      },
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "\n",
        "n_train_time = len(reframed)\n",
        "train = values[:n_train_time, :]\n",
        "test = values[n_train_time:, :]\n",
        "##test = values[n_train_time:n_test_time, :]\n",
        "# split into input and outputs\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "\n",
        "test_X = train_X\n",
        "test_y = train_y\n",
        "\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy-Vz-haErkn"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "# model.add(Dropout(0.2))\n",
        "# #    model.add(LSTM(70))\n",
        "# #    model.add(Dropout(0.3))\n",
        "# model.add(Dense(1))\n",
        "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "#CNN + LSTM\n",
        "model_cnn_lstm = Sequential()\n",
        "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None,train_X.shape[1], train_X.shape[2])))\n",
        "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model_cnn_lstm.add(TimeDistributed(Flatten()))\n",
        "model_cnn_lstm.add(LSTM(50, activation='relu'))\n",
        "model_cnn_lstm.add(Dense(1))\n",
        "model_cnn_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# fit network\n",
        "history = model.fit(train_X, train_y, epochs=20, batch_size=70, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# make a prediction\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], 7))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = np.concatenate((yhat, test_X[:, -7:]), axis=1)\n",
        "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = np.concatenate((test_y, test_X[:, -7:]), axis=1)\n",
        "# inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvHLjIUFJ4Ot"
      },
      "source": [
        "result = pd.DataFrame(inv_yhat,index=x_train.index[:-7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bejxcl8EKc1B"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIx5OEqIoEI"
      },
      "source": [
        "ax = plt.plot(inv_y)\n",
        "ax = plt.plot(inv_yhat)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On2X8K8oS6tT"
      },
      "source": [
        "match_test_data = retail_test_data.index\n",
        "hour_converted = []\n",
        "for i in match_test_data:\n",
        "  hour_converted.append(i.strftime('%Y-%m-%d %H:00:00'))\n",
        "\n",
        "new_result = result\n",
        "new_result['map'] = new_result.index.strftime('%Y-%m-%d %H:00:00')\n",
        "new_result.columns = ['c','map']\n",
        "new_result.index = new_result['map']\n",
        "replace_dict = new_result['c'].to_dict()\n",
        "retail_test_data['predictions'] = retail_test_data.index.strftime('%Y-%m-%d %H:00:00')\n",
        "retail_test_data['predictions'].replace(replace_dict,inplace=True)\n",
        "future_predictions = {'2011-12-09 08:00:00':2.23021,'2011-12-09 09:00:00':2.23021,'2011-12-09 10:00:00':2.23021,'2011-12-09 11:00:00':2.23021,'2011-12-09 12:00:00':2.23021}\n",
        "retail_test_data['predictions'].replace(future_predictions,inplace=True)\n",
        "\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RzLmU_SmTJi"
      },
      "source": [
        " retail_test_data['predictions'] = np.round(retail_test_data['predictions'].astype(float),decimals=2)\n",
        "retail_test_data.sort_values('order',inplace=True)\n",
        "UnitPrice = pd.DataFrame(retail_test_data['predictions'].astype('float').values,columns=['UnitPrice'])\n",
        "UnitPrice.to_csv('/content/drive/My Drive/TheGreatIndianHiringHackathon/'+'kkcnnlstm05'+'.csv', index=False, index_label=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlXDforbc4F_"
      },
      "source": [
        "fg = pd.read_csv('/content/kklstm01.csv')\n",
        "fg.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz43iqRC0OOO"
      },
      "source": [
        "c = retail_data.sort_index()\n",
        "c.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMQ2THux0ehU"
      },
      "source": [
        "h = retail_test_data.sort_index()\n",
        "h.tail(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ys2vDCesodw"
      },
      "source": [
        "# #SARIMAX\n",
        "# model = SARIMAX(y_train, order=(3,1,0),seasonal_order=(1,0,0,7), seasonal=True, enforce_invertibility=False, enforce_stationarity=False,exog=x_train)\n",
        "# sarimax_results = model.fit()\n",
        "# predictions = sarimax_results.predict(start=x_train.index[0], end=x_train.index[-1],exog=x_test)\n",
        "# plt.figure(figsize=(20,5))\n",
        "# ax = plt.plot(y_train)\n",
        "# ax = plt.plot(predictions)\n",
        "# plt.show()\n",
        "# #One thing that could be done is by distributing the day prediction accross the time stamps of that day. could reduce the error.\n",
        "# mean_squared_error(y_train,predictions)\n",
        "# # mean_prediction=predictions\n",
        "# # mean_prediction.loc[:] = np.round(y_train.mean(),decimals=2)\n",
        "# # match_predictions(mean_prediction,retail_test_data,'kkmean10')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}